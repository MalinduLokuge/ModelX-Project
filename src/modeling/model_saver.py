"""Model saver for deployment - save everything needed for inference"""
import joblib
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional


class ModelSaver:
    """Save trained models and pipelines for deployment"""

    def __init__(self, output_dir: Path, logger=None):
        self.output_dir = Path(output_dir)
        self.logger = logger

    def save_deployment_package(
        self,
        model: Any,
        preprocessor: Any = None,
        feature_engineer: Any = None,
        metadata: Dict[str, Any] = None,
        package_name: str = "deployment_model"
    ) -> Path:
        """
        Save complete deployment package

        Args:
            model: Trained model object
            preprocessor: Preprocessing pipeline
            feature_engineer: Feature engineering pipeline
            metadata: Model metadata (metrics, config, etc.)
            package_name: Name for the deployment package

        Returns:
            Path to saved package directory
        """

        # Create package directory
        package_dir = self.output_dir / package_name
        package_dir.mkdir(parents=True, exist_ok=True)

        if self.logger:
            self.logger.info(f"Saving deployment package to {package_dir}")

        # Save model
        model_path = package_dir / "model.pkl"
        joblib.dump(model, model_path)
        if self.logger:
            self.logger.info(f"  ✓ Model saved: {model_path.name}")

        # Save preprocessor if provided
        if preprocessor is not None:
            preprocessor_path = package_dir / "preprocessor.pkl"
            joblib.dump(preprocessor, preprocessor_path)
            if self.logger:
                self.logger.info(f"  ✓ Preprocessor saved: {preprocessor_path.name}")

        # Save feature engineer if provided
        if feature_engineer is not None:
            feature_engineer_path = package_dir / "feature_engineer.pkl"
            joblib.dump(feature_engineer, feature_engineer_path)
            if self.logger:
                self.logger.info(f"  ✓ Feature engineer saved: {feature_engineer_path.name}")

        # Save metadata
        if metadata is None:
            metadata = {}

        metadata.update({
            'saved_at': datetime.now().isoformat(),
            'package_name': package_name,
            'files': {
                'model': 'model.pkl',
                'preprocessor': 'preprocessor.pkl' if preprocessor else None,
                'feature_engineer': 'feature_engineer.pkl' if feature_engineer else None
            }
        })

        metadata_path = package_dir / "metadata.json"
        with open(metadata_path, 'w') as f:
            json.dump(metadata, f, indent=2)

        if self.logger:
            self.logger.info(f"  ✓ Metadata saved: {metadata_path.name}")

        # Create inference template
        self._create_inference_script(package_dir, metadata)

        if self.logger:
            self.logger.success(f"✓ Deployment package saved: {package_dir}")

        return package_dir

    def _create_inference_script(self, package_dir: Path, metadata: Dict[str, Any]):
        """Create inference.py template for deployment"""

        has_preprocessor = metadata['files']['preprocessor'] is not None
        has_feature_engineer = metadata['files']['feature_engineer'] is not None

        inference_code = f'''"""Inference script for deployed model
Generated by CompeteML on {metadata['saved_at']}

Usage:
    predictor = ModelPredictor('{package_dir.name}')
    predictions = predictor.predict(new_data_df)
"""

import joblib
import pandas as pd
from pathlib import Path


class ModelPredictor:
    """Load and use trained model for predictions"""

    def __init__(self, model_dir: str = '{package_dir.name}'):
        """
        Initialize predictor

        Args:
            model_dir: Path to model directory
        """
        self.model_dir = Path(model_dir)

        # Load model
        self.model = joblib.load(self.model_dir / 'model.pkl')

'''

        if has_preprocessor:
            inference_code += '''        # Load preprocessor
        self.preprocessor = joblib.load(self.model_dir / 'preprocessor.pkl')

'''

        if has_feature_engineer:
            inference_code += '''        # Load feature engineer
        self.feature_engineer = joblib.load(self.model_dir / 'feature_engineer.pkl')

'''

        inference_code += '''    def predict(self, df: pd.DataFrame):
        """
        Make predictions on new data

        Args:
            df: New data (same format as training data)

        Returns:
            Predictions array
        """

        df_processed = df.copy()

'''

        if has_preprocessor:
            inference_code += '''        # Preprocess
        df_processed = self.preprocessor.transform(df_processed)

'''

        if has_feature_engineer:
            inference_code += '''        # Engineer features
        df_processed = self.feature_engineer.transform(df_processed)

'''

        inference_code += '''        # Predict
        predictions = self.model.predict(df_processed)

        return predictions

    def predict_proba(self, df: pd.DataFrame):
        """
        Get prediction probabilities (classification only)

        Args:
            df: New data

        Returns:
            Probability array
        """

        df_processed = df.copy()

'''

        if has_preprocessor:
            inference_code += '''        df_processed = self.preprocessor.transform(df_processed)

'''

        if has_feature_engineer:
            inference_code += '''        df_processed = self.feature_engineer.transform(df_processed)

'''

        inference_code += '''        if hasattr(self.model, 'predict_proba'):
            return self.model.predict_proba(df_processed)
        else:
            raise ValueError("Model does not support probability predictions")


# Example usage
if __name__ == "__main__":
    # Initialize predictor
    predictor = ModelPredictor()

    # Load new data
    new_data = pd.read_csv("data/new_data.csv")

    # Make predictions
    predictions = predictor.predict(new_data)

    print(f"Predictions: {{predictions[:5]}}...")  # First 5
    print(f"Total predictions: {{len(predictions)}}")
'''

        # Save inference script
        inference_path = package_dir / "inference.py"
        with open(inference_path, 'w') as f:
            f.write(inference_code)

        if self.logger:
            self.logger.info(f"  ✓ Inference script created: {inference_path.name}")
